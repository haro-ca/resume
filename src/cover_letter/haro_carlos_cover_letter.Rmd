---
title: "Carlos A. Haro"
author: Carlos A. Haro
date: "`r Sys.Date()`"
output:
  pagedown::html_resume:
    # set it to true for a self-contained HTML page but it'll take longer to render
    self_contained: TRUE
    css: ['style.css', 'resume']
editor_options: 
  chunk_output_type: console
---

```{r Chunk options, echo=FALSE}
knitr::opts_chunk$set(warning = F, message = F, echo = FALSE, results = 'asis')
```

```{r Init}
options(tidyverse.quiet = TRUE)
library(tidyverse)
source(here::here('src', 'resume', 'print_functions.R'))
```


Aside
================================================================================

```{r Logo}
knitr::include_graphics(here::here('logo', 'ch.png'))
```


Contact Info {#contact}
--------------------------------------------------------------------------------

- <i class="fa fa-envelope"></i> haro_ca@outlook.com
- <i class="fa fa-twitter"></i> @[haro_ca_](https://twitter.com/haro_ca_)
- <i class="fa fa-github"></i> [haro-ca](https://github.com/haro-ca)

### *Why do I want to work at Ibotta?*
The type of data that Ibotta works with, as far as I can imagine, is micro-data 
(day-to-day consumer expenditure), as an economist, this is the kind of data that I find
most interesting. Further, I think the range of products that can be developed 
using such data has the most potential to add value, e.g. anything from product recommenders to
customer categorizers, even a simple regional heatmap adds value from this kind of data.
Lastly, I suppose that such a volume of data is handled with some cloud provider,
and it is my interest to further develop my skills in this topic.

### *How do I think I can help Ibotta?*
My current job at the Tax Administration Office has given me experience in handling micro-data, 
and I think this can be easily translated to your current business to add value.<br>
Suggesting products can only be done by looking at the data
(and this isn't possible via this cover letter), but I can outline the working values that I 
consider the basis for proper development of viable products:
teamwork, reproducibility, and openness. <br>
Their meaning to me is described in the last section of this cover letter. 

Disclaimer {#disclaimer}
--------------------------------------------------------------------------------

This cover letter was made with the R package [**pagedown**](https://github.com/rstudio/pagedown).

Last updated on `r Sys.Date()`.



Main
================================================================================

Carlos A. Haro {#title}
--------------------------------------------------------------------------------

### Data scientist with experience in economic analysis <br>  Currently searching for a data science position. <br><br>

### *Who am I?*
A data scientist and an economist fascinated by how
data science projects add value to an industry/organization.<br>
My answer, so far, is: by creating products and services that simplify, efficiently process, and
clearly communicate complex data.<br><br>
**Simplification**: In my experience, this isn't necessarily done by means of a model
(in fact, in my current organization, the answer rarely is a model);
a visualization, or a well written API can be just as effective.<br>
**Efficiency**: Solving a the problem with the least amount 
of resources. For a data product, this means: least amount of computational resources 
and programmer time. To minimize the former, programmer experience is needed; for the
latter, automation.<br>
**Communication**: The end product needs to be easily available to other members of the organization, 
and to the end user (client, decision taker).<br><br>
As an example: take a pipeline that starts at the DB Storage,
iterates through feature design and proper visualization,
proceeds to model training, deploys into a containerized service with a RESTful API, 
and through the API feeds a dashboard; all linked through multiple triggers.<br>
(This can be further expanded: proper logging, unit testing, CI/CD, and much more.)<br><br>
I find simplication and communication a common task among data scientists/analysts;
efficiency, on the other hand, is something I've seen most frequent
in engineering positions (ML engineers, DevOps).<br>
My interest lies in this intersection, and I'm looking for a role that allows me to
develop in it. 

### *Experience and skillset*
<div class='pull-left'>
[*Outliers*](https://en.wikipedia.org/wiki/Outliers_(book)),
a book by [Malcolm Gladwell](https://en.wikipedia.org/wiki/Malcolm_Gladwell), states that 
mastery over a skill can only be achieved by 10,000 hours of productive work.
While there is both evidence in favor and against this theory, I do find it a good proxy for
maturity of a skillset. The chart on the right attempts to summarize my current progress.
</div>

<div class='pull-right'>
```{r, echo=FALSE} 
library(tidyverse)
library(extrafont)
tribble(~R, ~Python, ~SQL, ~Makefiles, ~Docker, ~Cloud,
         3000,  300, 250, 100, 60, 100) %>% 
  pivot_longer(cols = everything(), names_to = 'language', values_to = 'hours') %>% 
  mutate(str_hours = if_else(str_length(hours) >= 4, 
                             str_c(str_sub(hours, end = 1L), 'K'), 
                             as.character(hours))) %>% 
  arrange(hours) %>% 
  mutate(hours = if_else(language == 'R', 500, hours),
         language = forcats::fct_inorder(language)) %>% 
  ggplot() +
  aes(x = language, y = hours, label = str_hours) +
  geom_col(width = 0.1, color = 'black', fill = 'black') +
  geom_point(color = 'black', fill = '#cecece', shape = 21, size = 20, stroke = 2) + 
  geom_text(color = 'black', size = 7) +
  geom_abline(aes(intercept = 380, slope = 5), size = 3, color = 'white') +
  geom_abline(aes(intercept = 400, slope = 5), size = 3, color = 'white') +
  scale_y_continuous(limits = seq(0, 520, by = 520)) +
  #scale_x_discrete(expand = expansion(mult = c(0, 0))) +
  labs(x = '', y = '', title = '') +
  theme_classic() +
  theme(axis.line.x = element_blank(), 
        axis.text.x = element_blank(), 
        axis.ticks.x = element_blank(), 
        title = element_text(size = 20, family = 'Serif'),
        axis.text.y = element_text(size = 20, family = 'Serif')) +
  coord_flip()
```

</div>

<p>
I've dedicated most of time to R programming (3000+ hours), this makes it my 
default workhorse for everything, ranging from all types of data analysis (modeling, dashboards, visualizations,
scraping, DB queries) to presentations and documents, everything (even this cover letter and the logo).<br>
However, the efficiency part of my goals has driven me to work to a moderate extent with python
(~300 hours, mainly with *pandas* and *scikit*, but some to *flask*, and *mlflow*); and to other
extent doing DevOps tasks: Makefiles (bash) for data pipelines automation,
and the basics of Docker (running,  stopping, and version controlling containerized apps).<br>
I've done ~200 hours of work with SQL, which make me comfortable "moving around" a DB; however, 
I recognize a far superior familiarity in the logic of handling Dataframes instead of Databases. <br>
In terms of cloud work, I've done ~100 hours of work, half of it because of personal interest 
in AWS, the other half is accounted by my current organization recently moving to a cloud provider.<br>
I also enjoy teaching. I've taught three courses for current my organization, the Tax Administration Office, 
staff's training, they've included topics of version control using git, data pipelines using Makefiles,
and general data handling and visualization in R.<br>
I'm currently teaching a course of tools for data analysis at my *alma mater*, [ITAM](https://www.itam.mx/) 
[(Syllabus download link)](https://github.com/haro-ca/herramientas_de_analisis_de_datos/raw/master/00_temario/temario.pdf).<br>
(Disclaimer: I'm not hired by ITAM, these are *pro-bono* classes taught from a former student to 
current students interested in the topics.)
</p>

### *Values description*  
*(This section descibes a set of working values that I consider the basis for a proper development of
viable products)*<br><br>
**Teamwork**:  I've discovered that helping each other inside a team, even if it's just a line of code, is
the only way to create a viable product.<br><br>
**Reproducibility**: Refers to the efficiency/automation/engineering part of the development. This needs
to be considered from day one, the very first Jupyter Notebook needs to already consider 
how the analysis can be automated and used in production.<br><br>
**Openness**: The general availability of the whole product, from the inner workings to the UI. The far
end of this are open-source projects, however, it can be done within an organization, e.g.
there doesn't need to be visibility restrictions of the work within teammates or from a team to the other,
all work needs to be publicly avaible for every person within the organization
(of course, with due security measures taken into account). This ensures non-duplicacy of work,
day-to-day learning from others, idea spreading, and any-time review of the current progress of a
development.<br><br>
It is my believe that the first two are enough to add value to an industry, and it is very likely
that Ibotta has them (if this is the case, take this section as a proof that I think our values
align and I can help you).
The third one is hard, and I don't expect it to be a part of Ibotta, but I hope it serves 
as an example of the type of philosophy that I want to create within an organization.

